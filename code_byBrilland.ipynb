{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53506df4-488f-47d4-b464-e49ed48dc8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\HP\\\\Documents\\\\ISE\\\\ISE2\\\\MachineLearning2\\\\Projet_final'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b118d3-4a02-460d-b7c9-0bc29f12c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.chdir(\"c:\\\\Users\\\\HP\\\\Documents\\\\ISE\\\\ISE2\\\\MachineLearning2\\\\Projet_final\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661c64bb-e767-4b60-aabd-d07a0c82b34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------\n",
    "# 1. Import des bibliothèques\n",
    "# ----------------------------\n",
    "import pandas as pd                   # Manipulation de données tabulaires\n",
    "import json                          # Pour parser les chaînes JSON (ex: genres)\n",
    "import re                            # Pour expressions régulières (nettoyage de texte)\n",
    "import nltk                          # Bibliothèque NLP (lemmatisation, stop-words)\n",
    "import numpy as np                   # Calcul numérique et manipulation de vecteurs\n",
    "import joblib                        # Sauvegarde/chargement d’objets (modèles, vecteurs)\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords                    # Stop-words anglais\n",
    "from nltk.stem import WordNetLemmatizer              # Lemmatisation des mots\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDF vectorisation\n",
    "from sklearn.decomposition import TruncatedSVD       # Réduction dimensionnelle (LSA)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Téléchargement des stop-words\n",
    "# ----------------------------\n",
    "nltk.download(\"stopwords\")   # Téléchargement des stop-words anglais\n",
    "nltk.download(\"wordnet\")     # Ressources pour la lemmatisation\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Chargement du CSV brut\n",
    "# ----------------------------\n",
    "df0 = pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "\n",
    "# On ne conserve que les 3 colonnes utiles\n",
    "df = df0[[\"original_title\", \"overview\", \"genres\"]].copy()\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Extraction et nettoyage des genres\n",
    "# ----------------------------\n",
    "def extract_genre_list(genres_str):\n",
    "    \"\"\"\n",
    "    Transforme la chaîne Python-JSON en liste de noms.\n",
    "    Exemples d'entrée :\n",
    "      \"[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}]\"\n",
    "    Retourne une chaîne \"Animation|Comedy\" ou \"\" si vide/mal formée.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 4.1 Remplacement des quotes pour JSON valide\n",
    "        js = genres_str.replace(\"'\", '\"')\n",
    "        items = json.loads(js)\n",
    "        # 4.2 Extraction des noms de genres\n",
    "        names = [g[\"name\"] for g in items if \"name\" in g]\n",
    "        return \"|\".join(names)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# Application de l'extraction\n",
    "df[\"genres\"] = df[\"genres\"].astype(str).apply(extract_genre_list)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Nettoyage du texte (overview)\n",
    "# ----------------------------\n",
    "# Initialisation du lemmatizer et des stop-words anglais\n",
    "stop_en = set(stopwords.words(\"english\"))\n",
    "lemm    = WordNetLemmatizer()\n",
    "\n",
    "def clean_overview(text):\n",
    "    \"\"\"\n",
    "    Nettoyage de l'overview :\n",
    "    - mise en minuscules\n",
    "    - suppression de tout ce qui n'est pas alphanumérique\n",
    "    - tokenisation simple, suppression des stop-words et lemmatisation\n",
    "    \"\"\"\n",
    "    # 5.1 Passage en minuscules et suppression ponctuation\n",
    "    t = re.sub(r\"[^a-z0-9\\s]\", \" \", text.lower())\n",
    "    # 5.2 Lemmatisation et filtrage\n",
    "    tokens = [\n",
    "        lemm.lemmatize(w)\n",
    "        for w in t.split()\n",
    "        if w not in stop_en and len(w) > 2\n",
    "    ]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Application du nettoyage\n",
    "df[\"clean_overview\"] = df[\"overview\"].fillna(\"\").apply(clean_overview)\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Filtrage des films sans genre\n",
    "# ----------------------------\n",
    "# On ne garde que les lignes où 'genres' n'est pas vide\n",
    "df = df[df[\"genres\"].str.strip() != \"\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c44b8e-0ea9-4b42-a427-6a909805f87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                     original_title  \\\n",
       "0                        Toy Story   \n",
       "1                          Jumanji   \n",
       "2                 Grumpier Old Men   \n",
       "3                Waiting to Exhale   \n",
       "4      Father of the Bride Part II   \n",
       "...                            ...   \n",
       "43019              Caged Heat 3000   \n",
       "43020                   Robin Hood   \n",
       "43021                      رگ خواب   \n",
       "43022          Siglo ng Pagluluwal   \n",
       "43023                     Betrayal   \n",
       "\n",
       "                                                overview  \\\n",
       "0      Led by Woody, Andy's toys live happily in his ...   \n",
       "1      When siblings Judy and Peter discover an encha...   \n",
       "2      A family wedding reignites the ancient feud be...   \n",
       "3      Cheated on, mistreated and stepped on, the wom...   \n",
       "4      Just when George Banks has recovered from his ...   \n",
       "...                                                  ...   \n",
       "43019  It's the year 3000 AD. The world's most danger...   \n",
       "43020  Yet another version of the classic epic, with ...   \n",
       "43021        Rising and falling between a man and woman.   \n",
       "43022  An artist struggles to finish his work while a...   \n",
       "43023  When one of her hits goes wrong, a professiona...   \n",
       "\n",
       "                         genres  \\\n",
       "0       Animation|Comedy|Family   \n",
       "1      Adventure|Fantasy|Family   \n",
       "2                Romance|Comedy   \n",
       "3          Comedy|Drama|Romance   \n",
       "4                        Comedy   \n",
       "...                         ...   \n",
       "43019           Science Fiction   \n",
       "43020      Drama|Action|Romance   \n",
       "43021              Drama|Family   \n",
       "43022                     Drama   \n",
       "43023     Action|Drama|Thriller   \n",
       "\n",
       "                                          clean_overview  \n",
       "0      led woody andy toy live happily room andy birt...  \n",
       "1      sibling judy peter discover enchanted board ga...  \n",
       "2      family wedding reignites ancient feud next doo...  \n",
       "3      cheated mistreated stepped woman holding breat...  \n",
       "4      george bank recovered daughter wedding receive...  \n",
       "...                                                  ...  \n",
       "43019  year 3000 world dangerous woman banished remot...  \n",
       "43020  yet another version classic epic enough variat...  \n",
       "43021                           rising falling man woman  \n",
       "43022  artist struggle finish work storyline cult pla...  \n",
       "43023  one hit go wrong professional assassin end sui...  \n",
       "\n",
       "[43024 rows x 4 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4967ec40-d96b-4bbc-abb2-c0911a5af9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier préparé : tmdb_for_lsa.csv (43024 films avec genre)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 7. Sauvegarde du DataFrame préparé\n",
    "# ----------------------------\n",
    "output_csv = \"tmdb_for_lsa.csv\"\n",
    "df[[\"original_title\", \"clean_overview\", \"genres\"]].to_csv(\n",
    "    output_csv, index=False, encoding=\"utf-8-sig\"\n",
    ")\n",
    "print(f\"✅ Fichier préparé : {output_csv} ({len(df)} films avec genre)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ccae2c-036c-48eb-a400-c2e4c7fff4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 20:04:07 INFO Chargé 43024 films depuis tmdb_for_lsa.csv\n",
      "2025-06-02 20:04:12 INFO TF-IDF construit : matrice creuse de forme (43024, 17981)\n",
      "2025-06-02 20:04:49 INFO LSA entraîné : projection en dimension 300\n",
      "2025-06-02 20:04:50 INFO Vectorizer TF-IDF sauvegardé sous tfidf_vectorizer.joblib\n",
      "2025-06-02 20:04:50 INFO Modèle LSA sauvegardé sous lsa_model.joblib\n",
      "2025-06-02 20:04:52 INFO Données LSA sauvegardées sous lsa_data.npz\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 8. Construction du modèle LSA\n",
    "# ----------------------------\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CONFIGURATION DU LOGGING\n",
    "# -----------------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8.1 Vérification de l'existence du fichier préparé\n",
    "# -----------------------------------------------------------------------------\n",
    "INPUT_CSV    = \"tmdb_for_lsa.csv\"\n",
    "VECTORIZER_PATH = \"tfidf_vectorizer.joblib\"\n",
    "LSA_MODEL_PATH  = \"lsa_model.joblib\"\n",
    "LSA_DATA_PATH   = \"lsa_data.npz\"\n",
    "\n",
    "if not os.path.isfile(INPUT_CSV):\n",
    "    logging.error(f\"Fichier introuvable : {INPUT_CSV}\")\n",
    "    raise FileNotFoundError(f\"Veuillez générer {INPUT_CSV} avant d'exécuter ce script.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8.2 Chargement du DataFrame préparé\n",
    "# -----------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "titles           = df[\"original_title\"].values      # liste des titres\n",
    "clean_overviews  = df[\"clean_overview\"].values      # liste des textes nettoyés\n",
    "\n",
    "logging.info(f\"Chargé {len(df)} films depuis {INPUT_CSV}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8.3 TF-IDF : vectorisation du corpus\n",
    "# -----------------------------------------------------------------------------\n",
    "try:\n",
    "    # 8.3.1 Remplacer tout NaN par chaîne vide\n",
    "    # --------------------------------------------------\n",
    "    # clean_overviews est un numpy array ou une liste de pandas Series\n",
    "    # On reconstruit une liste 100% string :\n",
    "    corpus = [doc if isinstance(doc, str) else \"\" for doc in clean_overviews]\n",
    "\n",
    "    # 8.3.2 Instanciation du vectorizer TF-IDF\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_df=0.8,        # ignorer les termes trop fréquents\n",
    "        min_df=5,          # ignorer les termes trop rares\n",
    "        norm=\"l2\",         # normalisation L2 des vecteurs\n",
    "        sublinear_tf=True  # tf = 1 + log(tf)\n",
    "    )\n",
    "    # 8.3.3 Apprentissage et transformation\n",
    "    X_tfidf = vectorizer.fit_transform(corpus)\n",
    "    logging.info(f\"TF-IDF construit : matrice creuse de forme {X_tfidf.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(\"Erreur lors de la vectorisation TF-IDF\")\n",
    "    logging.exception(e)\n",
    "    raise\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8.4 Entraînement du modèle LSA (SVD tronquée)\n",
    "# -----------------------------------------------------------------------------\n",
    "try:\n",
    "    n_components = 300\n",
    "    lsa = TruncatedSVD(\n",
    "        n_components=n_components,\n",
    "        algorithm=\"randomized\",\n",
    "        n_iter=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    X_lsa = lsa.fit_transform(X_tfidf)\n",
    "    logging.info(f\"LSA entraîné : projection en dimension {n_components}\")\n",
    "except Exception as e:\n",
    "    logging.error(\"Erreur lors de l'entraînement du modèle LSA\")\n",
    "    raise\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8.5 Sauvegarde des artefacts pour réutilisation\n",
    "# -----------------------------------------------------------------------------\n",
    "try:\n",
    "    joblib.dump(vectorizer, VECTORIZER_PATH)\n",
    "    logging.info(f\"Vectorizer TF-IDF sauvegardé sous {VECTORIZER_PATH}\")\n",
    "    \n",
    "    joblib.dump(lsa, LSA_MODEL_PATH)\n",
    "    logging.info(f\"Modèle LSA sauvegardé sous {LSA_MODEL_PATH}\")\n",
    "    \n",
    "    # Sauvegarde des vecteurs et des titres (pour recommandation)\n",
    "    np.savez(\n",
    "        LSA_DATA_PATH,\n",
    "        X_lsa   = X_lsa,\n",
    "        titles  = titles\n",
    "    )\n",
    "    logging.info(f\"Données LSA sauvegardées sous {LSA_DATA_PATH}\")\n",
    "except Exception as e:\n",
    "    logging.error(\"Erreur lors de la sauvegarde des artefacts\")\n",
    "    raise\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8.6 Fonction de recommandation \"générale\"\n",
    "# -----------------------------------------------------------------------------\n",
    "def recommend_general(user_title, top_n=10):\n",
    "    \"\"\"\n",
    "    Donne les top_n films les plus similaires à user_title.\n",
    "    Même si user_title n'existe pas dans la base, on le vectorise et compare\n",
    "    dans l'espace LSA des descriptions.\n",
    "    \"\"\"\n",
    "    # 1) Charger les artefacts si besoin\n",
    "    if not hasattr(recommend_general, \"vectorizer\"):\n",
    "        recommend_general.vectorizer = joblib.load(VECTORIZER_PATH)\n",
    "        recommend_general.lsa        = joblib.load(LSA_MODEL_PATH)\n",
    "        data = np.load(LSA_DATA_PATH, allow_pickle=True)\n",
    "        recommend_general.X_lsa      = data[\"X_lsa\"]\n",
    "        recommend_general.titles     = data[\"titles\"]\n",
    "        logging.info(\"Artefacts de recommandation chargés\")\n",
    "    \n",
    "    vec = recommend_general.vectorizer\n",
    "    model = recommend_general.lsa\n",
    "    X_train_lsa = recommend_general.X_lsa\n",
    "    titles = recommend_general.titles\n",
    "    \n",
    "    # 2) Vectorisation du titre utilisateur\n",
    "    tfidf_ut = vec.transform([user_title])\n",
    "    lsa_ut   = model.transform(tfidf_ut)\n",
    "    \n",
    "    # 3) Calcul des similarités cosinus\n",
    "    sims = cosine_similarity(lsa_ut, X_train_lsa).flatten()\n",
    "    \n",
    "    # 4) Tri des indices par score décroissant\n",
    "    idxs = np.argsort(sims)[::-1][:top_n]\n",
    "    \n",
    "    # 5) Affichage des recommandations\n",
    "    print(f\"\\n🎬 Recommandations pour « {user_title} » :\")\n",
    "    for i in idxs:\n",
    "        print(f\" - {titles[i]}  (score : {sims[i]:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbffa87-4a51-42f1-bb5a-fa6b36d26ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7781997f-37e0-4350-99bd-7d9ceafc8390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 20:04:54 INFO Artefacts de recommandation chargés\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎬 Recommandations pour « Inception » :\n",
      " - The N Word  (score : 0.613)\n",
      " - Double Take  (score : 0.531)\n",
      " - Back Issues: The Hustler Magazine Story  (score : 0.426)\n",
      " - Programming The Nation?  (score : 0.422)\n",
      " - Silly Little Game  (score : 0.395)\n",
      " - Cane Toads: The Conquest  (score : 0.372)\n",
      " - Antonio Gaudí  (score : 0.364)\n",
      " - Can't You Hear the Wind Howl? The Life & Music of Robert Johnson  (score : 0.364)\n",
      " - L'età di Cosimo de Medici  (score : 0.360)\n",
      " - Patience (After Sebald)  (score : 0.352)\n",
      "\n",
      "🎬 Recommandations pour « A Space Odyssey » :\n",
      " - The Dream Is Alive  (score : 0.894)\n",
      " - Lost in Space  (score : 0.758)\n",
      " - Hail Columbia!  (score : 0.749)\n",
      " - キャプテンハーロック  (score : 0.713)\n",
      " - Manhunt in Space  (score : 0.703)\n",
      " - Nukes in Space  (score : 0.689)\n",
      " - A Beautiful Planet  (score : 0.661)\n",
      " - The Phantom Planet  (score : 0.634)\n",
      " - Sergeant Dead Head  (score : 0.631)\n",
      " - The Man from Planet X  (score : 0.628)\n",
      "\n",
      "🎬 Recommandations pour « Titanic » :\n",
      " - Raise the Titanic  (score : 0.509)\n",
      " - Titanic II  (score : 0.475)\n",
      " - The Sea Hawk  (score : 0.467)\n",
      " - Blackbeard, the Pirate  (score : 0.451)\n",
      " - A Night to Remember  (score : 0.449)\n",
      " - Titanic: The Final Word with James Cameron  (score : 0.447)\n",
      " - Men Without Women  (score : 0.439)\n",
      " - Titanic  (score : 0.437)\n",
      " - Sarmaşık  (score : 0.437)\n",
      " - Poseidon  (score : 0.429)\n",
      "\n",
      "🎬 Recommandations pour « Batman » :\n",
      " - Batman: Under the Red Hood  (score : 0.465)\n",
      " - Batman: Bad Blood  (score : 0.464)\n",
      " - Shor in the City  (score : 0.444)\n",
      " - The Dark Knight Rises  (score : 0.439)\n",
      " - LEGO DC Comics Super Heroes: Justice League - Gotham City Breakout  (score : 0.432)\n",
      " - Batman: The Dark Knight Returns, Part 2  (score : 0.422)\n",
      " - Batman & Robin  (score : 0.417)\n",
      " - Batman Beyond Darwyn Cooke's Batman 75th Anniversary Short  (score : 0.406)\n",
      " - The Phenix City Story  (score : 0.403)\n",
      " - Batman: The Dark Knight Returns, Part 1  (score : 0.397)\n",
      "\n",
      "🎬 Recommandations pour « Toy story » :\n",
      " - Crude  (score : 0.923)\n",
      " - Τα κόκκινα φανάρια  (score : 0.916)\n",
      " - الرسالة‎  (score : 0.893)\n",
      " - The Message  (score : 0.873)\n",
      " - La regina dei tartari  (score : 0.867)\n",
      " - The Rolling Stones: Cocksucker Blues  (score : 0.866)\n",
      " - Mothers and Daughters  (score : 0.809)\n",
      " - Extraordinary Tales  (score : 0.792)\n",
      " - Les Saveurs du palais  (score : 0.774)\n",
      " - Bessie  (score : 0.769)\n",
      "\n",
      "🎬 Recommandations pour « Superman » :\n",
      " - This Unnameable Little Broom  (score : 0.453)\n",
      " - Superman 75  (score : 0.446)\n",
      " - Batman: Strange Days  (score : 0.415)\n",
      " - Boogie, el Aceitoso  (score : 0.405)\n",
      " - Terror on the Midway  (score : 0.399)\n",
      " - Street of Crocodiles  (score : 0.396)\n",
      " - Look, Up in the Sky: The Amazing Story of Superman  (score : 0.383)\n",
      " - Lego Batman: The Movie - DC Super Heroes Unite  (score : 0.381)\n",
      " - Rehearsals for Extinct Anatomies  (score : 0.379)\n",
      " - Atom Man vs Superman  (score : 0.369)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "#### -----------------------------------------------------------------------------\n",
    "# 8.7 Exemple d'exécution si lancé directement\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Exemple de test\n",
    "    recommend_general(\"Inception\")\n",
    "    recommend_general(\"A Space Odyssey\")\n",
    "    recommend_general(\"Titanic\")\n",
    "    recommend_general(\"Batman\")\n",
    "    recommend_general(\"Toy story\")\n",
    "    recommend_general(\"Superman\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
