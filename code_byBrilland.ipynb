{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53506df4-488f-47d4-b464-e49ed48dc8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\HP\\\\Documents\\\\ISE\\\\ISE2\\\\MachineLearning2\\\\Projet_final'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b118d3-4a02-460d-b7c9-0bc29f12c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.chdir(\"c:\\\\Users\\\\HP\\\\Documents\\\\ISE\\\\ISE2\\\\MachineLearning2\\\\Projet_final\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661c64bb-e767-4b60-aabd-d07a0c82b34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------\n",
    "# 1. Import des biblioth√®ques\n",
    "# ----------------------------\n",
    "import pandas as pd                   # Manipulation de donn√©es tabulaires\n",
    "import json                          # Pour parser les cha√Ænes JSON (ex: genres)\n",
    "import re                            # Pour expressions r√©guli√®res (nettoyage de texte)\n",
    "import nltk                          # Biblioth√®que NLP (lemmatisation, stop-words)\n",
    "import numpy as np                   # Calcul num√©rique et manipulation de vecteurs\n",
    "import joblib                        # Sauvegarde/chargement d‚Äôobjets (mod√®les, vecteurs)\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords                    # Stop-words anglais\n",
    "from nltk.stem import WordNetLemmatizer              # Lemmatisation des mots\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDF vectorisation\n",
    "from sklearn.decomposition import TruncatedSVD       # R√©duction dimensionnelle (LSA)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2. T√©l√©chargement des stop-words\n",
    "# ----------------------------\n",
    "nltk.download(\"stopwords\")   # T√©l√©chargement des stop-words anglais\n",
    "nltk.download(\"wordnet\")     # Ressources pour la lemmatisation\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Chargement du CSV brut\n",
    "# ----------------------------\n",
    "df0 = pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "\n",
    "# On ne conserve que les 3 colonnes utiles\n",
    "df = df0[[\"original_title\", \"overview\", \"genres\"]].copy()\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Extraction et nettoyage des genres\n",
    "# ----------------------------\n",
    "def extract_genre_list(genres_str):\n",
    "    \"\"\"\n",
    "    Transforme la cha√Æne Python-JSON en liste de noms.\n",
    "    Exemples d'entr√©e :\n",
    "      \"[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}]\"\n",
    "    Retourne une cha√Æne \"Animation|Comedy\" ou \"\" si vide/mal form√©e.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 4.1 Remplacement des quotes pour JSON valide\n",
    "        js = genres_str.replace(\"'\", '\"')\n",
    "        items = json.loads(js)\n",
    "        # 4.2 Extraction des noms de genres\n",
    "        names = [g[\"name\"] for g in items if \"name\" in g]\n",
    "        return \"|\".join(names)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# Application de l'extraction\n",
    "df[\"genres\"] = df[\"genres\"].astype(str).apply(extract_genre_list)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Nettoyage du texte (overview)\n",
    "# ----------------------------\n",
    "# Initialisation du lemmatizer et des stop-words anglais\n",
    "stop_en = set(stopwords.words(\"english\"))\n",
    "lemm    = WordNetLemmatizer()\n",
    "\n",
    "def clean_overview(text):\n",
    "    \"\"\"\n",
    "    Nettoyage de l'overview :\n",
    "    - mise en minuscules\n",
    "    - suppression de tout ce qui n'est pas alphanum√©rique\n",
    "    - tokenisation simple, suppression des stop-words et lemmatisation\n",
    "    \"\"\"\n",
    "    # 5.1 Passage en minuscules et suppression ponctuation\n",
    "    t = re.sub(r\"[^a-z0-9\\s]\", \" \", text.lower())\n",
    "    # 5.2 Lemmatisation et filtrage\n",
    "    tokens = [\n",
    "        lemm.lemmatize(w)\n",
    "        for w in t.split()\n",
    "        if w not in stop_en and len(w) > 2\n",
    "    ]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Application du nettoyage\n",
    "df[\"clean_overview\"] = df[\"overview\"].fillna(\"\").apply(clean_overview)\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Filtrage des films sans genre\n",
    "# ----------------------------\n",
    "# On ne garde que les lignes o√π 'genres' n'est pas vide\n",
    "df = df[df[\"genres\"].str.strip() != \"\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c44b8e-0ea9-4b42-a427-6a909805f87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                     original_title  \\\n",
       "0                        Toy Story   \n",
       "1                          Jumanji   \n",
       "2                 Grumpier Old Men   \n",
       "3                Waiting to Exhale   \n",
       "4      Father of the Bride Part II   \n",
       "...                            ...   \n",
       "43019              Caged Heat 3000   \n",
       "43020                   Robin Hood   \n",
       "43021                      ÿ±⁄Ø ÿÆŸàÿßÿ®   \n",
       "43022          Siglo ng Pagluluwal   \n",
       "43023                     Betrayal   \n",
       "\n",
       "                                                overview  \\\n",
       "0      Led by Woody, Andy's toys live happily in his ...   \n",
       "1      When siblings Judy and Peter discover an encha...   \n",
       "2      A family wedding reignites the ancient feud be...   \n",
       "3      Cheated on, mistreated and stepped on, the wom...   \n",
       "4      Just when George Banks has recovered from his ...   \n",
       "...                                                  ...   \n",
       "43019  It's the year 3000 AD. The world's most danger...   \n",
       "43020  Yet another version of the classic epic, with ...   \n",
       "43021        Rising and falling between a man and woman.   \n",
       "43022  An artist struggles to finish his work while a...   \n",
       "43023  When one of her hits goes wrong, a professiona...   \n",
       "\n",
       "                         genres  \\\n",
       "0       Animation|Comedy|Family   \n",
       "1      Adventure|Fantasy|Family   \n",
       "2                Romance|Comedy   \n",
       "3          Comedy|Drama|Romance   \n",
       "4                        Comedy   \n",
       "...                         ...   \n",
       "43019           Science Fiction   \n",
       "43020      Drama|Action|Romance   \n",
       "43021              Drama|Family   \n",
       "43022                     Drama   \n",
       "43023     Action|Drama|Thriller   \n",
       "\n",
       "                                          clean_overview  \n",
       "0      led woody andy toy live happily room andy birt...  \n",
       "1      sibling judy peter discover enchanted board ga...  \n",
       "2      family wedding reignites ancient feud next doo...  \n",
       "3      cheated mistreated stepped woman holding breat...  \n",
       "4      george bank recovered daughter wedding receive...  \n",
       "...                                                  ...  \n",
       "43019  year 3000 world dangerous woman banished remot...  \n",
       "43020  yet another version classic epic enough variat...  \n",
       "43021                           rising falling man woman  \n",
       "43022  artist struggle finish work storyline cult pla...  \n",
       "43023  one hit go wrong professional assassin end sui...  \n",
       "\n",
       "[43024 rows x 4 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4967ec40-d96b-4bbc-abb2-c0911a5af9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier pr√©par√© : tmdb_for_lsa.csv (43024 films avec genre)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 7. Sauvegarde du DataFrame pr√©par√©\n",
    "# ----------------------------\n",
    "output_csv = \"tmdb_for_lsa.csv\"\n",
    "df[[\"original_title\", \"clean_overview\", \"genres\"]].to_csv(\n",
    "    output_csv, index=False, encoding=\"utf-8-sig\"\n",
    ")\n",
    "print(f\"‚úÖ Fichier pr√©par√© : {output_csv} ({len(df)} films avec genre)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ccae2c-036c-48eb-a400-c2e4c7fff4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 20:04:07 INFO Charg√© 43024 films depuis tmdb_for_lsa.csv\n",
      "2025-06-02 20:04:12 INFO TF-IDF construit : matrice creuse de forme (43024, 17981)\n",
      "2025-06-02 20:04:49 INFO LSA entra√Æn√© : projection en dimension 300\n",
      "2025-06-02 20:04:50 INFO Vectorizer TF-IDF sauvegard√© sous tfidf_vectorizer.joblib\n",
      "2025-06-02 20:04:50 INFO Mod√®le LSA sauvegard√© sous lsa_model.joblib\n",
      "2025-06-02 20:04:52 INFO Donn√©es LSA sauvegard√©es sous lsa_data.npz\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 8. Construction du mod√®le LSA\n",
    "# ----------------------------\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CONFIGURATION DU LOGGING\n",
    "# -----------------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8.1 V√©rification de l'existence du fichier pr√©par√©\n",
    "# -----------------------------------------------------------------------------\n",
    "INPUT_CSV    = \"tmdb_for_lsa.csv\"\n",
    "VECTORIZER_PATH = \"tfidf_vectorizer.joblib\"\n",
    "LSA_MODEL_PATH  = \"lsa_model.joblib\"\n",
    "LSA_DATA_PATH   = \"lsa_data.npz\"\n",
    "\n",
    "if not os.path.isfile(INPUT_CSV):\n",
    "    logging.error(f\"Fichier introuvable : {INPUT_CSV}\")\n",
    "    raise FileNotFoundError(f\"Veuillez g√©n√©rer {INPUT_CSV} avant d'ex√©cuter ce script.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8.2 Chargement du DataFrame pr√©par√©\n",
    "# -----------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "titles           = df[\"original_title\"].values      # liste des titres\n",
    "clean_overviews  = df[\"clean_overview\"].values      # liste des textes nettoy√©s\n",
    "\n",
    "logging.info(f\"Charg√© {len(df)} films depuis {INPUT_CSV}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8.3 TF-IDF : vectorisation du corpus\n",
    "# -----------------------------------------------------------------------------\n",
    "try:\n",
    "    # 8.3.1 Remplacer tout NaN par cha√Æne vide\n",
    "    # --------------------------------------------------\n",
    "    # clean_overviews est un numpy array ou une liste de pandas Series\n",
    "    # On reconstruit une liste 100% string :\n",
    "    corpus = [doc if isinstance(doc, str) else \"\" for doc in clean_overviews]\n",
    "\n",
    "    # 8.3.2 Instanciation du vectorizer TF-IDF\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_df=0.8,        # ignorer les termes trop fr√©quents\n",
    "        min_df=5,          # ignorer les termes trop rares\n",
    "        norm=\"l2\",         # normalisation L2 des vecteurs\n",
    "        sublinear_tf=True  # tf = 1 + log(tf)\n",
    "    )\n",
    "    # 8.3.3 Apprentissage et transformation\n",
    "    X_tfidf = vectorizer.fit_transform(corpus)\n",
    "    logging.info(f\"TF-IDF construit : matrice creuse de forme {X_tfidf.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(\"Erreur lors de la vectorisation TF-IDF\")\n",
    "    logging.exception(e)\n",
    "    raise\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8.4 Entra√Ænement du mod√®le LSA (SVD tronqu√©e)\n",
    "# -----------------------------------------------------------------------------\n",
    "try:\n",
    "    n_components = 300\n",
    "    lsa = TruncatedSVD(\n",
    "        n_components=n_components,\n",
    "        algorithm=\"randomized\",\n",
    "        n_iter=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    X_lsa = lsa.fit_transform(X_tfidf)\n",
    "    logging.info(f\"LSA entra√Æn√© : projection en dimension {n_components}\")\n",
    "except Exception as e:\n",
    "    logging.error(\"Erreur lors de l'entra√Ænement du mod√®le LSA\")\n",
    "    raise\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8.5 Sauvegarde des artefacts pour r√©utilisation\n",
    "# -----------------------------------------------------------------------------\n",
    "try:\n",
    "    joblib.dump(vectorizer, VECTORIZER_PATH)\n",
    "    logging.info(f\"Vectorizer TF-IDF sauvegard√© sous {VECTORIZER_PATH}\")\n",
    "    \n",
    "    joblib.dump(lsa, LSA_MODEL_PATH)\n",
    "    logging.info(f\"Mod√®le LSA sauvegard√© sous {LSA_MODEL_PATH}\")\n",
    "    \n",
    "    # Sauvegarde des vecteurs et des titres (pour recommandation)\n",
    "    np.savez(\n",
    "        LSA_DATA_PATH,\n",
    "        X_lsa   = X_lsa,\n",
    "        titles  = titles\n",
    "    )\n",
    "    logging.info(f\"Donn√©es LSA sauvegard√©es sous {LSA_DATA_PATH}\")\n",
    "except Exception as e:\n",
    "    logging.error(\"Erreur lors de la sauvegarde des artefacts\")\n",
    "    raise\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8.6 Fonction de recommandation \"g√©n√©rale\"\n",
    "# -----------------------------------------------------------------------------\n",
    "def recommend_general(user_title, top_n=10):\n",
    "    \"\"\"\n",
    "    Donne les top_n films les plus similaires √† user_title.\n",
    "    M√™me si user_title n'existe pas dans la base, on le vectorise et compare\n",
    "    dans l'espace LSA des descriptions.\n",
    "    \"\"\"\n",
    "    # 1) Charger les artefacts si besoin\n",
    "    if not hasattr(recommend_general, \"vectorizer\"):\n",
    "        recommend_general.vectorizer = joblib.load(VECTORIZER_PATH)\n",
    "        recommend_general.lsa        = joblib.load(LSA_MODEL_PATH)\n",
    "        data = np.load(LSA_DATA_PATH, allow_pickle=True)\n",
    "        recommend_general.X_lsa      = data[\"X_lsa\"]\n",
    "        recommend_general.titles     = data[\"titles\"]\n",
    "        logging.info(\"Artefacts de recommandation charg√©s\")\n",
    "    \n",
    "    vec = recommend_general.vectorizer\n",
    "    model = recommend_general.lsa\n",
    "    X_train_lsa = recommend_general.X_lsa\n",
    "    titles = recommend_general.titles\n",
    "    \n",
    "    # 2) Vectorisation du titre utilisateur\n",
    "    tfidf_ut = vec.transform([user_title])\n",
    "    lsa_ut   = model.transform(tfidf_ut)\n",
    "    \n",
    "    # 3) Calcul des similarit√©s cosinus\n",
    "    sims = cosine_similarity(lsa_ut, X_train_lsa).flatten()\n",
    "    \n",
    "    # 4) Tri des indices par score d√©croissant\n",
    "    idxs = np.argsort(sims)[::-1][:top_n]\n",
    "    \n",
    "    # 5) Affichage des recommandations\n",
    "    print(f\"\\nüé¨ Recommandations pour ¬´ {user_title} ¬ª :\")\n",
    "    for i in idxs:\n",
    "        print(f\" - {titles[i]}  (score : {sims[i]:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbffa87-4a51-42f1-bb5a-fa6b36d26ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7781997f-37e0-4350-99bd-7d9ceafc8390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 20:04:54 INFO Artefacts de recommandation charg√©s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Recommandations pour ¬´ Inception ¬ª :\n",
      " - The N Word  (score : 0.613)\n",
      " - Double Take  (score : 0.531)\n",
      " - Back Issues: The Hustler Magazine Story  (score : 0.426)\n",
      " - Programming The Nation?  (score : 0.422)\n",
      " - Silly Little Game  (score : 0.395)\n",
      " - Cane Toads: The Conquest  (score : 0.372)\n",
      " - Antonio Gaud√≠  (score : 0.364)\n",
      " - Can't You Hear the Wind Howl? The Life & Music of Robert Johnson  (score : 0.364)\n",
      " - L'et√† di Cosimo de Medici  (score : 0.360)\n",
      " - Patience (After Sebald)  (score : 0.352)\n",
      "\n",
      "üé¨ Recommandations pour ¬´ A Space Odyssey ¬ª :\n",
      " - The Dream Is Alive  (score : 0.894)\n",
      " - Lost in Space  (score : 0.758)\n",
      " - Hail Columbia!  (score : 0.749)\n",
      " - „Ç≠„É£„Éó„ÉÜ„É≥„Éè„Éº„É≠„ÉÉ„ÇØ  (score : 0.713)\n",
      " - Manhunt in Space  (score : 0.703)\n",
      " - Nukes in Space  (score : 0.689)\n",
      " - A Beautiful Planet  (score : 0.661)\n",
      " - The Phantom Planet  (score : 0.634)\n",
      " - Sergeant Dead Head  (score : 0.631)\n",
      " - The Man from Planet X  (score : 0.628)\n",
      "\n",
      "üé¨ Recommandations pour ¬´ Titanic ¬ª :\n",
      " - Raise the Titanic  (score : 0.509)\n",
      " - Titanic II  (score : 0.475)\n",
      " - The Sea Hawk  (score : 0.467)\n",
      " - Blackbeard, the Pirate  (score : 0.451)\n",
      " - A Night to Remember  (score : 0.449)\n",
      " - Titanic: The Final Word with James Cameron  (score : 0.447)\n",
      " - Men Without Women  (score : 0.439)\n",
      " - Titanic  (score : 0.437)\n",
      " - Sarma≈üƒ±k  (score : 0.437)\n",
      " - Poseidon  (score : 0.429)\n",
      "\n",
      "üé¨ Recommandations pour ¬´ Batman ¬ª :\n",
      " - Batman: Under the Red Hood  (score : 0.465)\n",
      " - Batman: Bad Blood  (score : 0.464)\n",
      " - Shor in the City  (score : 0.444)\n",
      " - The Dark Knight Rises  (score : 0.439)\n",
      " - LEGO DC Comics Super Heroes: Justice League - Gotham City Breakout  (score : 0.432)\n",
      " - Batman: The Dark Knight Returns, Part 2  (score : 0.422)\n",
      " - Batman & Robin  (score : 0.417)\n",
      " - Batman Beyond Darwyn Cooke's Batman 75th Anniversary Short  (score : 0.406)\n",
      " - The Phenix City Story  (score : 0.403)\n",
      " - Batman: The Dark Knight Returns, Part 1  (score : 0.397)\n",
      "\n",
      "üé¨ Recommandations pour ¬´ Toy story ¬ª :\n",
      " - Crude  (score : 0.923)\n",
      " - Œ§Œ± Œ∫œåŒ∫Œ∫ŒπŒΩŒ± œÜŒ±ŒΩŒ¨œÅŒπŒ±  (score : 0.916)\n",
      " - ÿßŸÑÿ±ÿ≥ÿßŸÑÿ©‚Äé  (score : 0.893)\n",
      " - The Message  (score : 0.873)\n",
      " - La regina dei tartari  (score : 0.867)\n",
      " - The Rolling Stones: Cocksucker Blues  (score : 0.866)\n",
      " - Mothers and Daughters  (score : 0.809)\n",
      " - Extraordinary Tales  (score : 0.792)\n",
      " - Les Saveurs du palais  (score : 0.774)\n",
      " - Bessie  (score : 0.769)\n",
      "\n",
      "üé¨ Recommandations pour ¬´ Superman ¬ª :\n",
      " - This Unnameable Little Broom  (score : 0.453)\n",
      " - Superman 75  (score : 0.446)\n",
      " - Batman: Strange Days  (score : 0.415)\n",
      " - Boogie, el Aceitoso  (score : 0.405)\n",
      " - Terror on the Midway  (score : 0.399)\n",
      " - Street of Crocodiles  (score : 0.396)\n",
      " - Look, Up in the Sky: The Amazing Story of Superman  (score : 0.383)\n",
      " - Lego Batman: The Movie - DC Super Heroes Unite  (score : 0.381)\n",
      " - Rehearsals for Extinct Anatomies  (score : 0.379)\n",
      " - Atom Man vs Superman  (score : 0.369)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s‚Äôest bloqu√© lors de l‚Äôex√©cution du code dans une cellule active ou une cellule pr√©c√©dente. \n",
      "\u001b[1;31mVeuillez v√©rifier le code dans la ou les cellules pour identifier une cause possible de l‚Äô√©chec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d‚Äôinformations. \n",
      "\u001b[1;31mPour plus d‚Äôinformations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "#### -----------------------------------------------------------------------------\n",
    "# 8.7 Exemple d'ex√©cution si lanc√© directement\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Exemple de test\n",
    "    recommend_general(\"Inception\")\n",
    "    recommend_general(\"A Space Odyssey\")\n",
    "    recommend_general(\"Titanic\")\n",
    "    recommend_general(\"Batman\")\n",
    "    recommend_general(\"Toy story\")\n",
    "    recommend_general(\"Superman\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
